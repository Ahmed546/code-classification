{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Text:\n",
      "private static class SavingTrustManager implements X509TrustManager {\n",
      "\n",
      "private final X509TrustManager tm;\n",
      "private X509Certificate[] chain;\n",
      "\n",
      "SavingTrustManager(X509TrustManager tm) {\n",
      "this.tm = tm;\n",
      "}\n",
      "\n",
      "public X509Certificate[] getAcceptedIssuers() {\n",
      "// This change has been done due to the following resolution advised for Java 1.7+\n",
      "// http://infposs.blogspot.kr/2013/06/installcert-and-java-7.html\n",
      "return new X509Certificate[0];\n",
      "//throw new UnsupportedOperationException() ;\n",
      "\n",
      "}\n",
      "\n",
      "public void checkClientTrusted(X509Certificate[] chain, String authType) throws CertificateException {\n",
      "throw new UnsupportedOperationException();\n",
      "\n",
      "}\n",
      "\n",
      "public void checkServerTrusted(X509Certificate[] chain, String authType) throws CertificateException {\n",
      "this.chain = chain;\n",
      "tm.checkServerTrusted(chain, authType) ;\n",
      "\n",
      "WARNING:tensorflow:From d:\\AI-Projects\\code-classification\\venv\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at huggingface/CodeBERTa-language-id were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Explanation:\n",
      "\n",
      "1. Create a private class SavingTrustManager that will hold the X509TrustManager and its chain.\n",
      "2. Create an empty array.\n",
      "3. In the constructor, we will return an empty list.\n",
      "4. In this case we will call the getAcceptedIssuers() method of the class.\n",
      "5. Return the empty array if there are no acceptable issuers.\n",
      "6. In other case, the call to this method will return null.\n",
      "\n",
      "\n",
      "Detected Language: java (Confidence: 99.99%)\n",
      "Author: Unknown\n",
      "Accuracy: 99.99%\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "from langid import classify\n",
    "import regex\n",
    "\n",
    "def analyze_code_snippet(image_path):\n",
    "    # Step 1: Extract text from the image using OCR\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        extracted_text = pytesseract.image_to_string(image)\n",
    "        print(f\"Extracted Text:\\n{extracted_text}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error extracting text:\", e)\n",
    "        return\n",
    "\n",
    "    # Step 2: Identify programming language\n",
    "    try:\n",
    "        code_detector = pipeline(\"text-classification\", model=\"huggingface/CodeBERTa-language-id\")\n",
    "        language_prediction = code_detector(extracted_text)\n",
    "        language = language_prediction[0]['label']\n",
    "        confidence = language_prediction[0]['score']\n",
    "        code_explainer = pipeline(\"summarization\", model=\"ashwinR/CodeExplainer\")\n",
    "        explanation = code_explainer(extracted_text)[0]['summary_text']\n",
    "        print(f\"Code Explanation:\\n{explanation}\")\n",
    "        print(f\"Detected Language: {language} (Confidence: {confidence:.2%})\")\n",
    "    except Exception as e:\n",
    "        print(\"Error identifying language:\", e)\n",
    "        language = None\n",
    "        confidence = None\n",
    "\n",
    "    # Step 3: Search for author's name\n",
    "    author_pattern = r'author\\s*[:=]\\s*[\"\\']?([\\w\\s]+)[\"\\']?'\n",
    "    author_match = regex.search(author_pattern, extracted_text, regex.IGNORECASE)\n",
    "    author = author_match.group(1) if author_match else \"Unknown\"\n",
    "    print(f\"Author: {author}\")\n",
    "\n",
    "    \n",
    "\n",
    "    # Step 4: Show accuracy metrics\n",
    "    if confidence is not None:\n",
    "        accuracy_score = confidence * 100\n",
    "        print(f\"Accuracy: {accuracy_score:.2f}%\")\n",
    "    else:\n",
    "        print(\"Accuracy: N/A\")\n",
    "\n",
    "    return {\"language\": language, \"author\": author, \"confidence\": confidence}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"D:\\AI-Projects\\code-classification\\data\\escline_InstallCert_InstallCert_part6.png\"  # Replace with your image path\n",
    "    analyze_code_snippet(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install transformers torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Step 1: Extract text and generate dataset\n",
    "def extract_text(image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path)\n",
    "        extracted_text = pytesseract.image_to_string(image)\n",
    "        return extracted_text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def detect_language_and_functionality(text):\n",
    "    try:\n",
    "        # Language detection\n",
    "        code_detector = pipeline(\"text-classification\", model=\"huggingface/CodeBERTa-language-classification\")\n",
    "        language_prediction = code_detector(text)\n",
    "        language = language_prediction[0]['label']\n",
    "        \n",
    "        # Code explanation\n",
    "        code_explainer = pipeline(\"text2text-generation\", model=\"Salesforce/codet5-large\")\n",
    "        explanation_prompt = f\"Explain the following {language} code:\\n{text}\"\n",
    "        explanation = code_explainer(explanation_prompt, max_length=512)[0]['generated_text']\n",
    "        \n",
    "        return language, explanation\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting language or functionality: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def extract_author(text):\n",
    "    author_pattern = r'author\\s*[:=]\\s*[\"\\']?([\\w\\s]+)[\"\\']?'\n",
    "    author_match = re.search(author_pattern, text, re.IGNORECASE)\n",
    "    return author_match.group(1) if author_match else \"Unknown\"\n",
    "\n",
    "def process_images(image_dir, output_csv):\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        fieldnames = ['filename', 'language', 'functionality', 'author']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for image_file in os.listdir(image_dir):\n",
    "            if image_file.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                image_path = os.path.join(image_dir, image_file)\n",
    "                print(f\"Processing {image_file}...\")\n",
    "\n",
    "                # Extract text from image\n",
    "                text = extract_text(image_path)\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                # Detect language and functionality\n",
    "                language, functionality = detect_language_and_functionality(text)\n",
    "\n",
    "                # Extract author (if available)\n",
    "                author = extract_author(text)\n",
    "\n",
    "                # Write to CSV\n",
    "                writer.writerow({\n",
    "                    'filename': image_file,\n",
    "                    'language': language,\n",
    "                    'functionality': functionality,\n",
    "                    'author': author\n",
    "                })\n",
    "\n",
    "# Step 2: Train a CNN model\n",
    "def load_dataset(image_dir, label_file):\n",
    "    # Load labels\n",
    "    labels = pd.read_csv(label_file)\n",
    "    labels['functionality'] = labels['functionality'].astype(str)  # Ensure functionality is string\n",
    "    \n",
    "    # Prepare an ImageDataGenerator for images\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1.0 / 255.0,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    train_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=image_dir,\n",
    "        x_col='filename',\n",
    "        y_col=['language', 'functionality'],  # Multi-output labels\n",
    "        target_size=(128, 128),  # Resize images to 128x128\n",
    "        batch_size=32,\n",
    "        subset='training',\n",
    "        class_mode='multi_output'\n",
    "    )\n",
    "    \n",
    "    validation_generator = datagen.flow_from_dataframe(\n",
    "        dataframe=labels,\n",
    "        directory=image_dir,\n",
    "        x_col='filename',\n",
    "        y_col=['language', 'functionality'],  # Multi-output labels\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        subset='validation',\n",
    "        class_mode='multi_output'\n",
    "    )\n",
    "    \n",
    "    return train_generator, validation_generator\n",
    "\n",
    "def build_cnn(input_shape, num_languages, num_functionalities):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        \n",
    "        # Language output\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_languages, activation='softmax', name='language_output'),\n",
    "        \n",
    "        # Functionality output\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_functionalities, activation='softmax', name='functionality_output'),\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_cnn(image_dir, label_file):\n",
    "    # Load dataset\n",
    "    train_generator, validation_generator = load_dataset(image_dir, label_file)\n",
    "    \n",
    "    # Model parameters\n",
    "    input_shape = (128, 128, 3)\n",
    "    num_languages = len(train_generator.class_indices['language'])\n",
    "    num_functionalities = len(train_generator.class_indices['functionality'])\n",
    "    \n",
    "    # Build and compile CNN model\n",
    "    model = build_cnn(input_shape, num_languages, num_functionalities)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'language_output': 'categorical_crossentropy',\n",
    "            'functionality_output': 'categorical_crossentropy'\n",
    "        },\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator\n",
    "    )\n",
    "    \n",
    "    # Save model\n",
    "    model.save('code_snippet_cnn.h5')\n",
    "    print(\"Model saved as 'code_snippet_cnn.h5'\")\n",
    "    return model\n",
    "\n",
    "# Step 3: Use the trained CNN for prediction\n",
    "def predict_snippet(model_path, image_path):\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Preprocess input image\n",
    "    image = load_img(image_path, target_size=(128, 128))\n",
    "    image_array = img_to_array(image) / 255.0  # Normalize\n",
    "    image_array = image_array.reshape(1, 128, 128, 3)\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model.predict(image_array)\n",
    "    language_pred = predictions[0]\n",
    "    functionality_pred = predictions[1]\n",
    "    \n",
    "    print(\"Predicted Language:\", language_pred)\n",
    "    print(\"Predicted Functionality:\", functionality_pred)\n",
    "\n",
    "# Main execution pipeline\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Process images to generate dataset\n",
    "    image_dir = \"images/\"  # Directory containing code snippet images\n",
    "    output_csv = \"labels.csv\"  # Output CSV file\n",
    "    process_images(image_dir, output_csv)\n",
    "    \n",
    "    # Step 2: Train CNN on the generated dataset\n",
    "    train_cnn(image_dir, output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "def train_cnn(image_dir, label_file):\n",
    "    # Load dataset\n",
    "    train_generator, validation_generator = load_dataset(image_dir, label_file)\n",
    "    \n",
    "    # Model parameters\n",
    "    input_shape = (128, 128, 3)\n",
    "    num_languages = len(train_generator.class_indices['language'])\n",
    "    num_functionalities = len(train_generator.class_indices['functionality'])\n",
    "    \n",
    "    # Build and compile CNN model\n",
    "    model = build_cnn(input_shape, num_languages, num_functionalities)\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss={\n",
    "            'language_output': 'categorical_crossentropy',\n",
    "            'functionality_output': 'categorical_crossentropy'\n",
    "        },\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Set up a checkpoint to save the model with the best validation accuracy\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath='best_model.h5',  # Save model to this file\n",
    "        monitor='val_loss',  # Monitor validation loss (you can also monitor 'val_accuracy')\n",
    "        verbose=1,\n",
    "        save_best_only=True,  # Only save the model with the best validation loss\n",
    "        mode='min'  # Save when 'val_loss' is minimized\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=10,\n",
    "        validation_data=validation_generator,\n",
    "        callbacks=[checkpoint]  # Add the checkpoint callback\n",
    "    )\n",
    "    \n",
    "    print(\"Training complete. Best model saved as 'best_model.h5'\")\n",
    "    return model, history\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
